<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Autumn-Cat</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Autumn-Cat">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;index.html">
<meta property="og:site_name" content="Autumn-Cat">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Autumn-Cat" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Autumn-Cat</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/10/22/hello-world/" class="article-date">
  <time datetime="2019-10-22T10:29:06.099Z" itemprop="datePublished">2019-10-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/10/22/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/10/22/hello-world/" data-id="ck21ppygq000hk4qn1rflc8eo" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-0-1背包问题" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/06/23/0-1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/" class="article-date">
  <time datetime="2019-06-23T12:47:01.000Z" itemprop="datePublished">2019-06-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">数据结构与算法</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/06/23/0-1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/">0-1背包问题</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="0-1-背包问题"><a href="#0-1-背包问题" class="headerlink" title="0-1 背包问题"></a>0-1 背包问题</h1><h2 id="问题简述"><a href="#问题简述" class="headerlink" title="问题简述"></a>问题简述</h2><p>有N件物品和一个容量为V的背包。第i件物品的费用是c[i]，价值是w[i]。求解将哪些物品装入背包可使价值总和最大。</p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>数据如下</p>
<p><img src="https://pic1.zhimg.com/80/v2-85236598e4e35b7efa3ea3f69a5ca8ec_hd.jpg" alt="img"></p>
<h2 id="贪婪算法"><a href="#贪婪算法" class="headerlink" title="贪婪算法"></a>贪婪算法</h2><p>反例如下</p>
<p><img src="https://pic1.zhimg.com/80/v2-a5b61fdcb98cf9653effba39ba9a4ccc_hd.jpg" alt="img"></p>
<h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><h3 id="初始思路"><a href="#初始思路" class="headerlink" title="初始思路"></a>初始思路</h3><p>定义一个子问题P(i,w)：在前i个物体（物体按照体积排序）挑选重量不超过W的物体，使得总价值最大，记为m(i,w)。</p>
<p>现在只考虑第i个物体，则可能有两种情况</p>
<ul>
<li><p>选第i个物体，则问题变为P(i-1,w)</p>
</li>
<li><p>不选第i个问题，则问题变为P(i-1.W-wi)</p>
</li>
</ul>
<p>即递推公式为：<br>$$<br>  m(i,w) = max{m(i-1,W),(m(i-1,W-wi)+vi)}<br>$$<br>  如图所示：<br>  <img src="https://pic1.zhimg.com/80/v2-1d8090c991ca13cee3cb43c027b72304_hd.jpg" alt="img"></p>
<p>则按照上例，结果为：<br><img src="https://pic1.zhimg.com/80/v2-b24e97b8043a02c12313c3143e4dca20_hd.jpg" alt="img"></p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>考虑到上述表格，我们可以发现表格一些关键点特别重要，即新选了物体进入背包的关键点。</p>
<p>例如下图边缘处节点，之后都是边缘处节点的重复</p>
<p><img src="https://pic1.zhimg.com/80/v2-29d1a004c395ebe53e4161dad64a785c_hd.jpg" alt="img"></p>
<p>由此我们得到新的递推公式：<br>$$<br>dp(W) = max{dp(W),dp(W-wi)+vi}<br>$$</p>
<h3 id="初始化细节"><a href="#初始化细节" class="headerlink" title="初始化细节"></a>初始化细节</h3><p>常见的0-1背包问题可能又分两种</p>
<ul>
<li><p>要求背包必须装满</p>
</li>
<li><p>不一定背包必须装满</p>
</li>
</ul>
<p>对于这两种，分别有两种初始化</p>
<ul>
<li><p>将dp数组初始化为0</p>
</li>
<li><p>将dp数组初始化为-$\infty$</p>
</li>
</ul>
<p>解释：$-\infty$对空的惩罚更大，所以当初始化为$-\infty$会使得完全装满</p>
<h2 id="参考博客"><a href="#参考博客" class="headerlink" title="参考博客"></a>参考博客</h2>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/06/23/0-1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/" data-id="ck21ppyg60000k4qngod5379n" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dp/" rel="tag">dp</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ubuntu18-04-cuda-cudnn-Anaconda-一个人工智障的自我修养" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/20/ubuntu18-04-cuda-cudnn-Anaconda-%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E9%9A%9C%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/" class="article-date">
  <time datetime="2018-10-20T07:18:04.000Z" itemprop="datePublished">2018-10-20</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%9D%82%E8%B0%88/">杂谈</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/20/ubuntu18-04-cuda-cudnn-Anaconda-%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E9%9A%9C%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/">ubuntu18.04----cuda,cudnn,Anaconda,一个人工智障的自我修养</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="cuda-cudnn-Anaconda历险记"><a href="#cuda-cudnn-Anaconda历险记" class="headerlink" title="cuda,cudnn,Anaconda历险记"></a>cuda,cudnn,Anaconda历险记</h1><p>在装好ubuntu18.04后，作为一个新晋人工智障，怎么能不来一发cuda，cudnn和Anacode呢。而此文仅以纪念踩过的坑。<br>附：电脑系统为ubuntu18.04，显卡为gtx1050ti。其他显卡需要自行查询是否支持cuda。</p>
<h2 id="CUDA"><a href="#CUDA" class="headerlink" title="CUDA"></a>CUDA</h2><p>cuda是Nvidia的一个并行计算的平台，tensorflow等框架的GPU加速都需要CUDA支持。所以怎么能不安装CUDA。</p>
<h3 id="驱动"><a href="#驱动" class="headerlink" title="驱动"></a>驱动</h3><p>CUDA需要Nvidia的驱动，而ubuntu的驱动不一定是原装驱动，所以要重新安装驱动</p>
<h4 id="卸载老驱动"><a href="#卸载老驱动" class="headerlink" title="卸载老驱动"></a>卸载老驱动</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br></pre></td></tr></table></figure>
<h4 id="禁止自带的nouveau-nvidia驱动"><a href="#禁止自带的nouveau-nvidia驱动" class="headerlink" title="禁止自带的nouveau nvidia驱动"></a>禁止自带的nouveau nvidia驱动</h4><ol>
<li>为了禁止自带的驱动，要代开blacklist-nouveau.conf：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/modprobe.d/blacklist-nouveau.conf</span><br></pre></td></tr></table></figure></li>
<li>在文件中添加止配置的内容：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blacklist nouveau</span><br><span class="line">options nouveau modeset=0</span><br></pre></td></tr></table></figure></li>
<li>更新:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo update-initramfs -u</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="安装新驱动"><a href="#安装新驱动" class="headerlink" title="安装新驱动"></a>安装新驱动</h4><p>在卸载了老的驱动之后需要重启，由于卸载了驱动，所以重启之后的电脑可能显示效果不佳，但是基本操作可以，如果不能进入图形化桌面，可以按 CTRL + ALT + F3/F4/F5/F6 键登录命令行模式，安装显卡驱动。</p>
<ol>
<li>确认之前的操作<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsmod | grep nouveau</span><br></pre></td></tr></table></figure>
如果没有相应进程就表示禁用成功</li>
<li>添加Graphic Drivers PPA<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure></li>
<li>查看合适的驱动版本<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ubuntu-drivers devices</span><br></pre></td></tr></table></figure>
  
图中为输出结果，其中driver后便是驱动不同版本名称，选择最新的（recommended）安装  </li>
<li>安装并重启<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nvidia-driver-410</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure></li>
<li>确认<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure>
通过这个命令你可以查看nvidia显卡的状态，包括进程、现存等信息。</li>
</ol>
<h3 id="GCC-版本问题"><a href="#GCC-版本问题" class="headerlink" title="GCC 版本问题"></a>GCC 版本问题</h3><p>CUDA9.0安装要求gcc/g++版本是5.x或者6.x，而ubuntu18.04的gcc/g++版本一般是7.0（可以通过gcc/g++ -v查看）。所以需要自己配置</p>
<ol>
<li>安装5.0<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install gcc-5</span><br><span class="line">sudo apt-get install g++-5</span><br></pre></td></tr></table></figure></li>
<li>替换<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-5 50</span><br><span class="line">sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-5 50</span><br></pre></td></tr></table></figure>
最后的50代表版本优先级，最后确认。</li>
<li>还原<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo update-alternatives --config gcc</span><br><span class="line">sudo update-alternatives --config g++</span><br></pre></td></tr></table></figure>
这个命令可以看到可选的gcc/g++版本。之后想要还原可以选择相应的序号。</li>
</ol>
<h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libgl1-mesa-glx libglu1-mesa libglu1-mesa-dev</span><br></pre></td></tr></table></figure>
<h3 id="安装cuda9-0"><a href="#安装cuda9-0" class="headerlink" title="安装cuda9.0"></a>安装cuda9.0</h3><p>在官网<a href="https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1704&target_type=runfilelocal" target="_blank" rel="noopener">cuda下载</a>选择Ubuntu,17.04(写文章时还没有18.04，以17.04替换，可以工作)，runfile（local），base installer下载。<br>然后安装（具体版本号可能会有不同）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sh cuda_9.0.176_384.81_linux.run</span><br></pre></td></tr></table></figure>
<p>注：安装前一定装好依赖，在安装时，前三个选项注意<br>第一个问题read EULA：选accept<br>第二个问题install on an unsupported configuration：选y（默认是no！！！）<br>第三个问题install Nvdia accelerated Graphics Driver：选no（之前已经装好）<br>其他的都可以default，y</p>
<h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>打开bashrc文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>添加路径：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda-9.0/bin<span class="variable">$&#123;PATH:+:$&#123;PATH&#125;</span>&#125;  </span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda-9.0/lib64<span class="variable">$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>激活</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>一个绿色（？？？？）的流体模拟软件,注意这里要求gcc/g++ 版本不能高于6</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/NVIDIA_CUDA-9.0_Samples/5_Simulations/fluidsGL</span><br><span class="line">make clean &amp;&amp; make</span><br><span class="line">./fluidsGL</span><br></pre></td></tr></table></figure>
<p>然后你就可以看见一潭绿色污水，用鼠标在上面滑动可以扰动这潭死水  </p>
  
<h2 id="CUDNN"><a href="#CUDNN" class="headerlink" title="CUDNN"></a>CUDNN</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>安装CUDNN非常简单，进入<a href="https://developer.nvidia.com/cudnn" target="_blank" rel="noopener">官网</a>（官网需要注册,要填写一堆东西后，登陆后才能下载）<br>选择下载(因为没有18.04 所以下16.04的，不过也能用)  </p>
<blockquote>
<p>cuDNN v7.3.1 Runtime Library for Ubuntu16.04 (Deb)<br>cuDNN v7.3.1 Developer Library for Ubuntu16.04 (Deb)<br>cuDNN v7.3.1 Code Samples and User Guide for Ubuntu16.04 (Deb)</p>
</blockquote>
<p>下载后可以直接安装deb文件</p>
<h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cp -r /usr/src/cudnn_samples_v7/ <span class="variable">$HOME</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$HOME</span>/cudnn_samples_v7/mnistCUDNN</span><br><span class="line">make clean &amp;&amp; make</span><br><span class="line">./mnistCUDNN</span><br></pre></td></tr></table></figure>
<p>这里cudnn版本不同对应文件夹名称也不同,最后出现test passed代表通过</p>
<h2 id="ANACONDA"><a href="#ANACONDA" class="headerlink" title="ANACONDA"></a>ANACONDA</h2><p>anaconda包含了一些数据处理的必要包</p>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><p>由于tensorflow目前只支持python3.6，故这里更推荐下载python3.6的anaconda版本，即为Python 3.6 (Anaconda 5.2.0).另外由于不可抗力，清华镜像下载更快。  </p>
<ul>
<li>官网下载为<a href="https://www.anaconda.com/download/#linux" target="_blank" rel="noopener">anaconda官网下载</a>。  </li>
<li>清华镜像下载地址为<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/" target="_blank" rel="noopener">清华镜像下载</a></li>
</ul>
<p>下载后</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-5.2.0-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>
<p>附：最后一个选项是安装VScode，一个很好用的编辑器。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/10/20/ubuntu18-04-cuda-cudnn-Anaconda-%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E9%9A%9C%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/" data-id="ck21ppygj0007k4qnd2ljcvpq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" rel="tag">环境配置</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-ubuntu18-04-基本安装与美化" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/10/19/ubuntu18-04-%E5%9F%BA%E6%9C%AC%E5%AE%89%E8%A3%85%E4%B8%8E%E7%BE%8E%E5%8C%96/" class="article-date">
  <time datetime="2018-10-19T14:26:30.000Z" itemprop="datePublished">2018-10-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%9D%82%E8%B0%88/">杂谈</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/10/19/ubuntu18-04-%E5%9F%BA%E6%9C%AC%E5%AE%89%E8%A3%85%E4%B8%8E%E7%BE%8E%E5%8C%96/">ubuntu18.04----基本配置与美化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="ubuntu18-04—-基本配置与美化"><a href="#ubuntu18-04—-基本配置与美化" class="headerlink" title="ubuntu18.04—-基本配置与美化"></a>ubuntu18.04—-基本配置与美化</h1><p>最近看ubuntu18.04发布，想着尝试一波，然而在配置环境的时候遇到了很多坑，先记录下来，以供参考。</p>
<h2 id="进入ubnuntu18-04"><a href="#进入ubnuntu18-04" class="headerlink" title="进入ubnuntu18.04"></a>进入ubnuntu18.04</h2><p>由于ubuntu18.04.1的驱动问题，所以你在关ubutnu的时候可能会卡死，非常正常，只要断电重启就行。<br>重启后如果运气不好，可能你会卡在logo界面，不要担心。这时要重启，在grub界面进入ubuntu advance那个选项，选择recovery，在里面选择resume选项就可以进入系统了。<br>等打好驱动后就不会这么卡。</p>
<h2 id="换源"><a href="#换源" class="headerlink" title="换源"></a>换源</h2><p>装好ubuntu18.04的第一件事就是换源，不然你在安装一些软件时可能会遇到各种找不到库的情况。<br>换源需要修改的配置文件为sources.list，在/etc/apt下  </p>
<ol>
<li>打开sources.list文件：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo gedit /etc/apt/sources.list</span><br></pre></td></tr></table></figure></li>
<li>在文件末尾添加源，这里列一些常见的源<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#网易163更新服务器（广东广州电信/联通千兆双线接入），包含其他开源镜像：</span></span><br><span class="line">deb http://mirrors.163.com/ubuntu/ wily main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ wily-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ wily-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ wily-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.163.com/ubuntu/ wily-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ wily main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ wily-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ wily-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ wily-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.163.com/ubuntu/ wily-backports main restricted universe multiverse</span><br><span class="line"></span><br><span class="line"><span class="comment">#阿里云更新服务器（北京万网/浙江杭州阿里云服务器双线接入），包含其他开源镜像：</span></span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiverse</span><br><span class="line">deb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse</span><br><span class="line"></span><br><span class="line"><span class="comment">#清华大学更新服务器，（教育网核心节点百兆接入，已计划提高到千兆）由清华大学学生网管会维护。包含其他开源镜像：</span></span><br><span class="line"><span class="comment"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-updates main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-backports main restricted universe multiverse</span></span><br><span class="line">deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse</span><br><span class="line"><span class="comment"># deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ bionic-security main restricted universe multiverse</span></span><br></pre></td></tr></table></figure>
然后更新<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt upgrate</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h2 id="驱动"><a href="#驱动" class="headerlink" title="驱动"></a>驱动</h2><p>一开始进入系统时可能会非常卡，甚至与打开设置都会卡死。这一般都是驱动的问题，现在换源后让系统帮你自动装好驱动。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ubuntu-drivers autoinstall</span><br></pre></td></tr></table></figure>
<p>执行完这个命令后，ubuntu18.04，应该就比较流畅了。</p>
<h2 id="中文输入法"><a href="#中文输入法" class="headerlink" title="中文输入法"></a>中文输入法</h2><p>ubuntu18.04配置中文输入法比较简单，只需要在设置里配置就行。</p>
<ol>
<li>首先进入设置，打开语言选项  </li>
<li>点击manage installed languages，安装必要的软件</li>
<li>在keyboard input method system中选择ibus或着xim。然后apply sysytem-wide</li>
<li>重启，进入设置语言选项，在input sources选择Chinese(intelligent pinyin)  </li>
</ol>
<p>然后就可以在top bar的语言选项中看到Chinese(intelligent pinyin) 选项了</p>
<h2 id="解决时间问题"><a href="#解决时间问题" class="headerlink" title="解决时间问题"></a>解决时间问题</h2><p>win-ubuntu双系统的电脑可能会出现时间问题，解决方案如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install ntpdate</span><br><span class="line">sudo ntpdate time.windows.com</span><br><span class="line">sudo hwclock --localtime --systohc</span><br></pre></td></tr></table></figure>

<h2 id="ss-可选"><a href="#ss-可选" class="headerlink" title="ss(可选)"></a>ss(可选)</h2><p>介绍略</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install shadowsocks-libev</span><br><span class="line">sudo gedit /etc/shadowsocks-libev/config.json（配置文件）</span><br><span class="line">sudo systemctl <span class="built_in">enable</span> shadowsocks-libev-local@config.service</span><br><span class="line">sudo systemctl start shadowsocks-libev-local@config.service（开机自启）</span><br></pre></td></tr></table></figure>

<h2 id="美化"><a href="#美化" class="headerlink" title="美化"></a>美化</h2><p>由于ubuntu18.04 桌面系统是gnome，所以美化起来非常容易。</p>
<h3 id="gnome-tweak-tools"><a href="#gnome-tweak-tools" class="headerlink" title="gnome-tweak-tools"></a>gnome-tweak-tools</h3><p>gnome-tweak-tool是一个美化gnome桌面的gui软件，这个软件使选择主题变得非常容易  </p>
<h4 id="安装gnome-tweak-tools"><a href="#安装gnome-tweak-tools" class="headerlink" title="安装gnome-tweak-tools"></a>安装gnome-tweak-tools</h4><p>先输入以下命令安装软件  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install gnome-tweak-tool</span><br></pre></td></tr></table></figure>
<p>然后就可以在软件列表中看到Tweaks<br>打开软件，在appearance中有就可以配置相关主题。</p>
<h3 id="解除shell的封印"><a href="#解除shell的封印" class="headerlink" title="解除shell的封印"></a>解除shell的封印</h3><p>在apperance中有一个选项shell是锁住的，想要解除这个选项的封印需要额外配置：</p>
<ol>
<li>安装chrome-gnome-shell，虽然有chrome之名，但是这个软件并不要求chrome，火狐也可以<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install chrome-gnome-shell</span><br></pre></td></tr></table></figure></li>
<li>浏览器（chrome or firefox）需要安装扩展，打开<a href="https://extensions.gnome.org/，" target="_blank" rel="noopener">https://extensions.gnome.org/，</a> 然后点击其中的Click here to install browser extension.然后就可以安装logo是脚丫子的GNOME Shell integration（附：或者直接在扩展商店中搜索）</li>
<li>如果你之前两步都完成了的话就可以打开<a href="https://extensions.gnome.org/，" target="_blank" rel="noopener">https://extensions.gnome.org/，</a> 选择安装User Themes：在extensions中搜索User Themes，点击进入User Themes，然后拨动开关到on就可以  </li>
</ol>
<p>这样tweaks的shell就可以用了<br>另外除了user themes，推荐另外几个不错的扩展  </p>
<ul>
<li>Dash to Dock：将dock放在中间，类似于mac的布局</li>
<li>Hide Top Bar：自动隐藏top bar</li>
</ul>
<p>其他的扩展可以依据个人喜好添加</p>
<h3 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h3><p>gnome-tweak-tools已经安装好，然而还却一个漂亮的主题。这里可以在<a href="https://www.gnome-look.org" target="_blank" rel="noopener">https://www.gnome-look.org</a>  下载自己喜欢的主题，shells，图标等相关的美化内容，然后解压复制到/usr/share/themes/文件夹下，重新打开Tweak就可以选择相应的主题来美化了</p>
<h2 id="作者自己的美化选择"><a href="#作者自己的美化选择" class="headerlink" title="作者自己的美化选择"></a>作者自己的美化选择</h2><p>经过一下午的甄别选择，作者本人选择了一套自认为比较简洁且漂亮的美化方案，以供参考  </p>
<h3 id="Tweaks"><a href="#Tweaks" class="headerlink" title="Tweaks"></a>Tweaks</h3><p>在Tweaks如下选择  </p>
<h4 id="applications"><a href="#applications" class="headerlink" title="applications"></a>applications</h4><p>打开<a href="https://www.gnome-look.org" target="_blank" rel="noopener">https://www.gnome-look.org</a> ，搜索McOS-themes，进入主页，点击download，选择一个主题。个人比较喜欢黑色，所以选择McOS-MJV-Dark-mode-Gnome下载。下载解压复制到/usr/share/themes/下，在Tweaks选择McOS-MJV-Dark-mode-Gnome</p>
<h4 id="Cursor"><a href="#Cursor" class="headerlink" title="Cursor"></a>Cursor</h4><p>选择自带的DMZ-White  </p>
<h4 id="ICons"><a href="#ICons" class="headerlink" title="ICons"></a>ICons</h4><p>选择自带的Ubuntu-mono-light，如果有需要可以选择下载图标包到/usr/share/icon中</p>
<h4 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h4><p>打开<a href="https://www.gnome-look.org" target="_blank" rel="noopener">https://www.gnome-look.org</a> ，搜索Flat Remix GNOME theme，点击进入Flat Remix GNOME theme主页，点击download选择Flat-Remix最新版本（个人选择3.30）下载，解压复制到/usr/share/themes/下，在Tweaks选择Flat-Remix</p>
<h3 id="gnome-extensions"><a href="#gnome-extensions" class="headerlink" title="gnome-extensions"></a>gnome-extensions</h3><p>在<a href="https://extensions.gnome.org/" target="_blank" rel="noopener">https://extensions.gnome.org/</a> 选择Dash to Dock，Hide Top Bar打开。</p>
<h3 id="终端"><a href="#终端" class="headerlink" title="终端"></a>终端</h3><p>打开Terminal，选择edit的perferences，可以在Use transparent background中调节终端透明度。<br>如果没办法调节的话，可以看看有没有先把Use colors from System theme的那个勾去掉。</p>
<h3 id="美化成果"><a href="#美化成果" class="headerlink" title="美化成果"></a>美化成果</h3>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/10/19/ubuntu18-04-%E5%9F%BA%E6%9C%AC%E5%AE%89%E8%A3%85%E4%B8%8E%E7%BE%8E%E5%8C%96/" data-id="ck21ppygi0006k4qn3f361xi1" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/linux/" rel="tag">linux</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Batch Normalization" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/30/Batch%20Normalization/" class="article-date">
  <time datetime="2018-09-30T03:28:43.000Z" itemprop="datePublished">2018-09-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/30/Batch%20Normalization/">Batch Normlization</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><h2 id="Batch-Normalization-1"><a href="#Batch-Normalization-1" class="headerlink" title="Batch Normalization"></a><strong>Batch Normalization</strong></h2><p>Batch Normalization由2015年论文<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">《Batch Normalization: Accelerating Deep Network Training by  Reducing Internal Covariate Shift》</a>提出，之后被广泛应用于各种网络。</p>
<h3 id="问题：Internal-Covariate-Shift"><a href="#问题：Internal-Covariate-Shift" class="headerlink" title="问题：Internal Covariate Shift"></a>问题：Internal Covariate Shift</h3><h4 id="Internal-Covariate-Shift的危害是什么"><a href="#Internal-Covariate-Shift的危害是什么" class="headerlink" title="Internal Covariate Shift的危害是什么"></a>Internal Covariate Shift的危害是什么</h4><p>在深层网络的训练中，由于网络参数的变化，内部节点的数据的分布也会随着发生变化，这个过程叫做Internal Covariate Shift。</p>
<p>简而言之，对于网络F，F(x)的分布为A，但是当F的参数发生改变，F(x)的便不一定服从A的分布。</p>
<h4 id="Internal-Covariate-Shift的危害"><a href="#Internal-Covariate-Shift的危害" class="headerlink" title="Internal Covariate Shift的危害"></a>Internal Covariate Shift的危害</h4><ol>
<li><strong>梯度消失</strong>：当我们在网络中使用饱和激励函数（saturated activation function），如sigmoid，不合理的x分布可能会位于饱和激励函数的饱和区，而这会导致梯度消失问题。</li>
<li><strong>上层网络不适应新的分布</strong>：神经网络学习过程本质就是为了学习数据分布（？？从贝叶斯的角度思考）当训练数据的分布发生变化，那么网络就要在每次迭代都去学习适应不同的分布，这样将会大大降低网络的训练速度。</li>
</ol>
<h3 id="Batch-Normalization做法"><a href="#Batch-Normalization做法" class="headerlink" title="Batch Normalization做法"></a>Batch Normalization做法</h3><h4 id="减缓Internal-Covariate-Shift"><a href="#减缓Internal-Covariate-Shift" class="headerlink" title="减缓Internal Covariate Shift"></a>减缓Internal Covariate Shift</h4><p>Internal Covariate Shift的主要问题在于分布会改变，那么对每一层输入的每个批次的特征做归一化处理，使得他们服从同一个分布。<br>归一化公式：<br>$$Norm(x) = \frac{x-mean(x)}{\sqrt{Var(x)+\epsilon}}$$<br>其中x包含一个batch的所有图片的某个特征点。</p>
<h4 id="维护数据的本来的表达能力"><a href="#维护数据的本来的表达能力" class="headerlink" title="维护数据的本来的表达能力"></a>维护数据的本来的表达能力</h4><p>正则化虽然可以保证数据的分布，但他也可能破坏原数据的表达能力，即神经网络通过训练学习将特征提取出来，然而正则化却将其破坏。</p>
<p>作者通过平移放缩来保证信息不会被丢失：<br>$$x = \gamma<em>Norm(x) + \beta = \gamma</em>\frac{x-mean(x)}{\sqrt{Var(x)+\epsilon}} + \beta$$</p>
<p>尤其是当<br>$\gamma = \sqrt{Var(x)+\epsilon} , \beta = mean(x)$ ,Batch Normalization不改变原来的值</p>
<h3 id="测试时的BN"><a href="#测试时的BN" class="headerlink" title="测试时的BN"></a>测试时的BN</h3><p>在测试时，往往一个batch只有一张图片，无法求出均值和方差。</p>
<p>这里我们在训练时得到训练样本的均值，其具体的更新的方式为：<br>$$ mean(All) = mean(batch) + mean(All) * (1-momentum)$$<br>$$ Var(All) = Var(batch) + Var(All) * (1-momentum)$$<br>每训练完一个batch，对$mean(All),Var(all)$更新一次（注：在正则化时使用的依旧是对应batch计算出的均值方差:$mean(batch),Var(batch)$）。当训练完成之后，我们将最后更新完的$mean(All),Var(all)$作为整体样本均值方差的估计。在测试，使用估计均值、方差来进行Batch normalization。</p>
<h2 id="Layer-Normlization、Group-Normlization"><a href="#Layer-Normlization、Group-Normlization" class="headerlink" title="Layer Normlization、Group Normlization"></a><strong>Layer Normlization、Group Normlization</strong></h2><p>LN和GN是BN的变种，其主要差别便是归一化的样本集不同。顾名思义BN的样本集是一个batch，LN是一个layer，GN是一个group。</p>
<p>由于后面两种正则化方式感觉用的不多，这里就不再赘述，详情可参考其他博客或是原论文。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/30/Batch%20Normalization/" data-id="ck21ppygd0002k4qn6s0gbf9s" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/cv/" rel="tag">cv</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-卷积神经网络及其结构" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/30/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8A%E5%85%B6%E7%BB%93%E6%9E%84/" class="article-date">
  <time datetime="2018-09-30T03:28:43.000Z" itemprop="datePublished">2018-09-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/30/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8A%E5%85%B6%E7%BB%93%E6%9E%84/">卷积神经网络及其结构</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="卷积神经网络及其结构"><a href="#卷积神经网络及其结构" class="headerlink" title="卷积神经网络及其结构"></a>卷积神经网络及其结构</h1><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>全连接神经网络有一个最大的缺点，就是它需要大量的参数，对于一个 $n1$ 个值输入 $n2$ 个值输出的一层网络，它需要的参数量是$n1*n2$，大量的参数使得模型变得更复杂，也更难训练 。</p>
<p>卷积操作利用权值共享来解决参数过多这个问题。卷积就是通过一个二维卷积核来卷积整个输入矩阵。卷积操作的过程这里不再赘述（可以参考其他博客或者CS231N或是参考文献【1】）。这里讨论一些更细节的东西。</p>
<h3 id="输入输出尺寸"><a href="#输入输出尺寸" class="headerlink" title="输入输出尺寸"></a>输入输出尺寸</h3><p>对于卷积操作一个重要问题是已知输入尺寸为$n<em>n$ ，卷积核的尺寸为 $k</em>k$ ，卷积步幅为$stride$，那么输出的尺寸是多少？</p>
<p>这里我的思路将卷积核的最左边的数作为哨兵，那么在初始情况这个哨兵的索引为$k$，每一次卷积，哨兵的索引加$stride$，那么我们可以得到如下公式：<br>$$<br>k+cnt<em>stride &lt; n<br>$$<br>即我们就可以得到最大的卷积次数：<br>$$<br>cnt = \frac{n-k}{stride}<br>$$<br>在卷积的时候，为了使得图片尺寸大小不变等原因，我们会在图像的周围填充0，这个就是padding操作。在padding之后，输入的尺寸就变成了$n+2</em>padding$，这时候卷积次数为：<br>$$<br>cnt = \frac{n-k+2*padding}{stride}<br>$$</p>
<p>则加上最开始的一次，我们就可以得到输出的尺寸为：$(cnt+1)*(cnt+1)$。</p>
<p>如果我们要使输入输出尺寸一致，这时候:<br>$$<br>padding = \frac{(n-1)*stride - n + k}{2}<br>$$<br> 对于常见的步幅1的卷积而言：<br>$$<br>padding = \frac{k-1}{2}<br>$$</p>
<h3 id="实现卷积"><a href="#实现卷积" class="headerlink" title="实现卷积"></a>实现卷积</h3><p>在Pytorch等框架中，卷积是通过矩阵乘法实现的：</p>
<p><img src="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8A%E5%85%B6%E7%BB%93%E6%9E%84%5C1566892088518.png" alt="1566892088518"></p>
<ul>
<li>input转成input matrix（img2col）：按照卷积核的卷积顺序，将被卷积的部分拉长作为行，这样一行行组成input matrix</li>
<li>kernel转成kernel matrix（sum）：将kernel拉长作为列，和对应input matrix的行相乘</li>
<li>将结果转化为标准形式（col2img）</li>
</ul>
<h3 id="一些卷积的变种："><a href="#一些卷积的变种：" class="headerlink" title="一些卷积的变种："></a>一些卷积的变种：</h3><ol>
<li>空洞卷积：它可以使得参数相同时，感受野更大。但是粒度也更加粗糙。</li>
</ol>
<p><img src="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8A%E5%85%B6%E7%BB%93%E6%9E%84%5C1566893766501.png" alt="1566893766501"></p>
<ol start="2">
<li><p>一横一竖卷积（？？？）：将$k<em>k$的卷积核，变成两个$(k</em>1)(1*k)$的卷积核。这样使得参数更小</p>
</li>
<li><p>可变行卷积：可变性卷积我认为是在空洞卷积的基础上拓展而来，可变性卷积希望通过训练改变卷积的形状，使其更适应物体的形状。</p>
<p>其具体的实现是通过给输入图片加上相应的偏移值$\Delta p$，来完成可变形卷积。（偏移值是可以训练改变的）</p>
</li>
<li><p>并行卷积结构：多个卷积层并列，并把它们的结果拼接输出(google inception结构)</p>
</li>
<li><p>残差链接：残差链接在反向传播的时候多加了一个传播通道（在链式法则项中加上恒等项1）；可以环境梯度消失问题，使得深层神经网络的训练更有效。另一种思考就是残差层使得深层神经网络可以退化成浅层神经网络，其实就是将多种层次的神经组合起来，形成了一种boostting。</p>
<p><img src="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8A%E5%85%B6%E7%BB%93%E6%9E%84%5C1567063624101.png" alt="1567063624101"></p>
</li>
</ol>
<h3 id="反卷积"><a href="#反卷积" class="headerlink" title="反卷积"></a>反卷积</h3><p>反卷积是一种上采样的方式（反向传播也是利用这种方式传播梯度的）。</p>
<p>卷积的过程就是图像中对应块（按一定步幅选取）和 filter 对应元素相乘并求和（这是一个缩小的过程，即将对应块的多个值加权为一个值）</p>
<p>反卷积和卷积相反，它将图片的一个值和 filter 相乘，按一定步幅组合成新的特征图。如下图所示：</p>
<p><img src="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8A%E5%85%B6%E7%BB%93%E6%9E%84%5C1567064251681.png" alt="1567064251681"></p>
<h2 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h2><p>池化分为平均池化和最大池化，池化的操作是很简单的。（此处略）</p>
<p>池化的作用如下：</p>
<ul>
<li><p>使感受野更大，池化使的特征图更小，相应的感受野更大</p>
</li>
<li><p>平移不变性，池化将不断抽象某个区域（通过最大或是平均），破坏了位置关系</p>
</li>
</ul>
<p>然而由于池化是对空间信息的破坏，所以Hinton认为池化的有效是一种灾难。然而池化对于细粒度的任务（检测？分割）会不会造成影响，这个目前我并不知道有没有相关论文做过描述。</p>
<h2 id="批量归一化"><a href="#批量归一化" class="headerlink" title="批量归一化"></a>批量归一化</h2><h3 id="Internal-Covariate-Shift"><a href="#Internal-Covariate-Shift" class="headerlink" title="Internal Covariate Shift"></a>Internal Covariate Shift</h3><p>深度神经网络作为一个系统，我们认为其上一层与下一层的耦合关系是十分紧密的。这种耦合关系BN作者认为主要是：上一层的输出是一种分布，那么训练好的下一层的函数往往会在这种分布下表现最好。（例如sigmoid函数在过大的数或过小的数就会出现饱和情况）</p>
<p>但是在训练过程中每一层的参数会被改变，这样就会导致每一层的输出的分布也会不断改变，这种改变被称为Internal Covariate Shift。ICS会带来以下问题：</p>
<ul>
<li><p>由于上层网络不断调整带来数据分布的变化，下一层也需要不断的调整自己，这使得学习速率更低。</p>
</li>
<li><p>数据的分布可能会陷入梯度饱和区，增大的训练的难度。</p>
</li>
</ul>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>ICS的核心问题就是参数的改变会引起分布的变化，那么解决思路便是对每一层的输出进行重新归一化，改变它的分布。</p>
<p>归一化公式如下：<br>$$<br>\hat{x} = \frac{x-E(x)}{\sqrt{Var(x)}+\epsilon}<br>$$<br>然而下一层所适应的归一化并不一定是 均值为0，方差为1 的分布，所以这里添加两个学习参数$\gamma,\beta$使得网络能够自己学习调整分布，归一化的公式就变为：<br>$$<br>y = \gamma*\hat{x}+\beta<br>$$<br>由此变得到了一个归一化的公式。</p>
<h3 id="训练与测试的BN"><a href="#训练与测试的BN" class="headerlink" title="训练与测试的BN"></a>训练与测试的BN</h3><p>在训练时，是对每一批训练数据进行归一化，即用的是每一批数据的均值和方差。</p>
<p>但是在测试的过程中，一个batch就是一张。所以这里有两种方法来估计测试的均值和方差：</p>
<ul>
<li><p>保存所有batch的方差$\mu_{bacth}$和方差$\sigma^2_{batch}$，然后再求出它们的无偏估计<br>$$<br>\mu_{test} = E(\mu_{batch})\<br>\sigma^2_{test} = \frac{m}{m-1}E(\sigma^2_{batch})<br>$$</p>
</li>
<li><p>对所有的batch的均值和方差进行移动加权平均来估计<br>$$<br>\mu_{test}=\mu_{batch}+\mu_{test}∗(1−momentum)\<br>\sigma^2_{test}=\sigma^2_{batch}+\sigma^2_{test}∗(1−momentum)<br>$$</p>
</li>
</ul>
<h2 id="训练trick"><a href="#训练trick" class="headerlink" title="训练trick"></a>训练trick</h2><h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><p>对于深度学习最重要的是数据，当数据量有限的时候可以通过一些trick来做数据增强，这里常用的有（主要针对图像）：</p>
<ul>
<li>图像裁剪：这里主要有随机裁剪和中心裁剪</li>
<li>图像翻转：水平/垂直/镜像翻转</li>
<li>尺度变化：放大和缩小</li>
<li>图像旋转：将图像旋转$15^o$等</li>
</ul>
<h3 id="防止过拟合"><a href="#防止过拟合" class="headerlink" title="防止过拟合"></a>防止过拟合</h3><p>防止过拟合基本的方法就是加入正则项（一阶正则 / 二阶正则）。</p>
<p>对于神经网络，Hinton提出一种方法叫Dropout。Dropout的做法是将神经元按照概率$p$失活（即设置为0）来训练。另外在失活之后，还要将权重乘上$\frac{1}{1-p}$来修正失活对输出的影响。如果没有该操作，那么在测试的时候（测试不需要失活），需要将权重乘上$p$。</p>
<p>Dropout的可能工作原理有解释如下：</p>
<p>Dropout相当于将多个模型结合起来。而这类似于   <em>生物遗传进化</em>（？？？），比一个要好。类似于boosting方法？？？？</p>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>虽然有时候网络中有BN来解决数据的分布问题，但是一个好的初始化往往直接决定了一个模型最终的表现效果（陷入哪个局部最优点）。这里一般介绍几种可能的参数初始化，一般用Xavier，然而总可以多试几个，说不定会有惊喜。。。</p>
<ul>
<li><p><strong>全零初始化</strong></p>
<p>全零初始化使得梯度为0，所以不可能会有好结果的。</p>
</li>
<li><p><strong>随机正态分布</strong></p>
<p>正态分布的均值为0，然而决定方差的时候需要谨慎。方差太小，就成了全零；方差太大，梯度容易爆炸。</p>
<p>而且随机初始化有一个缺陷就是它使得输入输出分布不一致。</p>
<p>假设输入$X \in N(0,1)$，那么输出为$Y = W<em>X$，这里W，N独立同分布，那么输出方差为：<br>$$<br>\begin{equation}<br>\begin{aligned}<br>Var(y)<br>&amp;=Var(w_1</em>x_1+w_2<em>x_2…+w_1</em>x_n)\<br>&amp;=Var(w_1)<em>Var(x_1)+Var(w_2)</em>Var(x_2)+…+Var(wn)*Var(x_n)\<br>\end{aligned}<br>\end{equation}<br>$$</p>
<p>由于$w_i,x_i$线性无关，所以：<br>$$<br>Var(w_i<em>x_i) = Var(w_i)</em>Var(x_i)<br>$$<br>由此输出的方差如下，其中n是输入节点的数量<br>$$<br>\begin{equation}<br>\begin{aligned}<br>Var(y) &amp;= \sum_{i=1}^nVar(w_i)Var(x_i)\<br>&amp;= n*Var(w_i)Var(x_i)\space\space\space\space\space同分布<br>\end{aligned}<br>\end{equation}<br>$$</p>
</li>
<li><p><strong>Xavier</strong></p>
<p>Xavier即是为了使输入输出分布相同提出的：<br>$$<br>Var(y) = Var(x)<br>$$<br>由上述推导得到：<br>$$<br>Var(y) = n<em>Var(w_i)</em>Var(x_i) = Var(x)\<br>Var(w_i) = 1/n<br>$$<br>在神经网络中，有前向和后向两个过程，所以我们需要综合考虑输入的节点数$n_{in}$和输出节点数$n_{out}$：<br>$$<br>Var(w_i) = \frac{2}{n_{in}+n_{out}}<br>$$<br>这里Xavier采用的是均匀分布（是否可以使用相应的正态分布？），由概率论知识，对于一个均匀分布$U(a,b)$，其方差为：<br>$$<br>Var = \frac{(b-a)^2}{12}<br>$$<br>解得应参数a，b得到：<br>$$<br>w \sim U(-\sqrt\frac{6}{n_{in}+n_{out}},\sqrt\frac{6}{n_{in}+n_{out}})<br>$$</p>
</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>【1】A guide to convolution arithmetic for deep learning</p>
<p>【2】<a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="noopener">《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/30/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8A%E5%85%B6%E7%BB%93%E6%9E%84/" data-id="ck21ppygo000dk4qnhstshn10" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-目标检测简单综述" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/30/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0/" class="article-date">
  <time datetime="2018-09-30T03:28:43.000Z" itemprop="datePublished">2018-09-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/30/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0/">Batch Normlization 、Layer Normlization、Group Normlization</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="目标检测的任务（Problem-Settings）"><a href="#目标检测的任务（Problem-Settings）" class="headerlink" title="目标检测的任务（Problem Settings）"></a>目标检测的任务（Problem Settings）</h2><p>目标检测的有两个任务：</p>
<ul>
<li>检测出该图片中物体的类别</li>
<li>检测出对应物体的位置（用一个框表示，即左上坐标和右下坐标）</li>
</ul>
<p>为了达成我们的目标我们需要一些度量（metric）来作为衡量标准，在目标检测一般使用如下度量：</p>
<ol>
<li><p><strong>IoU</strong> ：IoU是计算预测位置和目标位置的相差程度的一种度量，其优点是对大框和小框都有很好的适应性。它的计算公式如下：<br>$$<br>IoU = \frac{Area(box_{pred}\cap box_{gt})}{Area(box_{pred}\cup box_{gt})}<br>$$<br>确定好其计算的伪代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">pred:(x1,x2),(x3,x4)</span></span><br><span class="line"><span class="string">gt:(y1,y2),(y3,y4)</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="comment">#求出交叉区域面积</span></span><br><span class="line">in_1 = max(x1,y1)</span><br><span class="line">in_2 = max(x2,y2)</span><br><span class="line">in_3 = min(x3,y3)</span><br><span class="line">in_4 = min(x4,y4)</span><br><span class="line">inArea = getArea([in_1,in_2],[in_3,in_4])</span><br><span class="line"><span class="comment">#求出并区域面积</span></span><br><span class="line">area1 = getArea([x1,x2],[x3,x4])</span><br><span class="line">area2 = getArea([y1,y2],[y3,y4])</span><br><span class="line">outArea = area1+area2-inArea</span><br><span class="line"><span class="comment">#计算IoU</span></span><br><span class="line">IoU = outArea/inArea</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>cross entropy</strong>：交叉熵是分类任务的常见损失函数</p>
</li>
<li><p><strong>mAP、AP</strong>：</p>
<p>这一切要从precious和recall开始，其定义如下图所示：</p>
<p><img src="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0%5C1567155538247.png" alt="1567155538247"></p>
<p>简而言之，precision是针对预测的（猜的准确率如何）；recall是针对样本的（召回了多少正样本）。</p>
<p>我们需要综合precision和recall，而这就得到了AP。在目标检测时，我们会根据confidence score将检测 n个结果 排序（从大到小）。然后将这n个结果逐个加入集合中得到n个precision和recall（即只有第一个结果的，有第一个第二个，有第一个第二个第三个……）。然后我们将precision组成纵坐标recall组成横坐标得到一个曲线，precision是从 1 逐步下降，recall是从 0 逐步上升，所以我们得到了一个下降的曲线（PR curves）。而PR曲线围成的面积即为AP。</p>
<p>而针对计算面积的方式也有不同的方法，比较常用的是PASCAL和COCO的：</p>
<ul>
<li><p>PASCAL：2008年规则对precision进行平滑，平滑方法是对每一给precision，使用其右边最大的值，在实际使用中，常使用11点进行内插。后来2012改进了，直接求斜线面积（无数个点内插）</p>
<p><img src="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0%5C1567241120527.png" alt="1567241120527"></p>
</li>
<li><p>COCO：COCO的mAP就是AP，每一对其进行区分，它使用101个点进行内插 mAP。</p>
</li>
</ul>
</li>
</ol>
<ol start="4">
<li><strong>FPS</strong>：FPS对于一个实时的目标检测模型是非常重要的（在处理视频时）</li>
</ol>
<h2 id="模型思想"><a href="#模型思想" class="headerlink" title="模型思想"></a>模型思想</h2><p>神经网络虽然在分类任务表现出色，但是如果要移植到检测任务上，需要解决三个问题：</p>
<ol>
<li>图片中有些地方有物体，有些地方没有物体。如何确定物体的位置</li>
<li>图片中有多个物体，如何对多个物体进行检测</li>
<li>图片中有些物体大，有些物体小，如何检测出这些多尺度的物体</li>
</ol>
<p>针对如上问题，主要有两种解决思路，一种是one-stage的，还有一种是two-stage</p>
<h3 id="two-stage"><a href="#two-stage" class="headerlink" title="two-stage"></a>two-stage</h3><p>two-stage的思想是将检测分为两步：</p>
<ul>
<li>确定图片中有物体的部分</li>
<li>将该部分送入神经网络中确定类别以及位置</li>
</ul>
<p>一开始的神经网络是暴力的，它就是用不同大小的框滑动选取图片的部分，然后再去做一个物体的分类和定位。然而这种思想太过简略，太没有利用到图片的信息来进行选框。</p>
<p><strong>R-CNN</strong></p>
<p>R-CNN提出可以利用图片中的纹理、边缘、颜色等信息来粗粒度的选取物体可能出现的位置，即候选区域（Region Proposal）。</p>
<p>然而R-CNN有如下问题：</p>
<ul>
<li>将每一个区域都作为CNN的输入，时间开销很大</li>
<li>由于CNN的输入是固定的，而候选区域的形状大小是不确定的。所以需要对候选区域进行形变，但这会造成失真。</li>
</ul>
<p><strong>SPP-net</strong></p>
<p>SPP-net解决了R-CNN的缺点。它首先将一整张图片输入CNN，提取得到特征图。然后将对应候选区域的特征图裁剪出来，这大大减小了时间开销。</p>
<p>然而特征图之后的全连接网络的输入要求是一个固定的大小，所以SPP提出了 空间金字塔池化（Spatial Pyramid Pooling，SPP池化）。</p>
<p>SPP池化的核心是改变的池化的大小（池化一般是$2<em>2$的格子中进行池化）。它将特征图分为$4</em>4$、$2<em>2$、$1</em>1$个格子，分别在这些格子中进行池化。得到一个固定的$16+4+1$的向量。</p>
<p>SPP-net的过程是：单张图片+一次CNN+多个proposal region特征图+多个pooling+多次分类回归。它将多个proposal region特征图存放到磁盘中，然后再分布进行分类回归。这一过程有两个缺点：</p>
<ul>
<li>磁盘的多次读写的时间开销大</li>
<li>这一过程不是端到端的。所以再训练的时候，需要训练好前面的特征提取网络，再固定参数，训练之后的全连接网络。</li>
</ul>
<p><strong>Fast-RCNN</strong></p>
<p>Fast-RCNN修正了SPP-net。它最大的改进是不再将多个proposal region特征图 进行多次回归了。它在将多个特征图进行ROI pooling之后拼接为一个向量。然后直接做分类回归。</p>
<p>ROI pooling是SPP的一个简化版，即它不再将特征图划分为$4<em>4,2</em>2,1<em>1$，而是直接划分为$n</em>n$份。</p>
<p>ROI pooling有一个小缺点是有时候region proposal特征图不一定能够被n整除。所以后来的mask RCNN提出ROI align，当不能整除时，用双线性插值的方式求出浮点数坐标的特征值。</p>
<p><strong>Faster-RCNN</strong></p>
<p>Faster-RCNN是two-stage算法的巅峰之作。它最大的贡献是提出了RPN（region proposal net）。使得选取ROI变成可以学习的。Faster-RCNN的大致流程如下：</p>
<ol>
<li>back bone提取特征图</li>
<li>RPN以特征图作为输入，得到ROI的坐标与第一次类别</li>
<li>结合特征图以及ROI 坐标 得到region proposal特征图</li>
<li>将region proposal特征图送入全连接网络做回归和分类</li>
</ol>
<p><em>附：Faster-RCNN提出了anchor box，然而这个已经不局限于one-stage和two-stage了，所以我将其放在了优化思路中</em></p>
<h3 id="one-stage"><a href="#one-stage" class="headerlink" title="one-stage"></a>one-stage</h3><p>目标的检测的源头都是滑动窗口（sliding windows）。two stage的演化思路方法是改进proposal region的选取方法以及使得将two stage尽量放在一个网络中（网络中的两个部分）。</p>
<p>one-stage的想法更加激进，它认为卷积的操作实际就 可以对应了滑动窗口的滑动部分，卷积得到的特征图中的特征点，就是对应感受野提取出的结果，这里感受野可以类似于滑动剪切的窗口。</p>
<p>YOLO v1是one-stage的开篇之作，他将图片分成$7<em>7$个格子。图片中的物体落在哪个格子中，哪个格子就负责预测该物体。最后输出的特征图是$7*7</em>(C+[confidence,location])$，相当于每个格子预测1个物体（实际上YOLO设计的要更加巧妙，每个格子预测2个物体，通过confidence来共享C），C为类别概率，location为位置信息。这里需要提醒的是，物体的大小可以远大于该格子，因为通过不断的卷积，最后提取的信息远大于那个格子。在损失函数的设计上，YOLO通过将 正样本损失、负样本损失、分类损失、回归损失 都乘以不同权重来调整样本不平衡问题。（优化思路中详细描述）</p>
<p>无疑YOLO v1的设计现在看来是比较简陋的，它有如下问题：</p>
<ul>
<li>最后输出的不同结果 对应原图的感受野都是相同的，这样对于不同尺度物体的匹配程度较差</li>
<li>每一个格子只能预测1个物体（可以设置为多个物体，但v1作者只是设置了2个，由此看来更多可能有一些问题）</li>
<li>YOLO v1是直接 对于坐标 的预测，而结果的感受野不是全图。（坐标肯定是要基于全图左上角作为基准才能得到）</li>
</ul>
<p>针对如上问题，有很多巧妙的方法被提出。这里简单介绍一下SSD和YOLO v2的anchor思想。具体参见优化思路。</p>
<p>SSD针对不同尺度的物体，使用最后五个特征图来预测。越深处的特征图的感受野越大，可以负责预测更大的物体，反之可以预测更小的物体。</p>
<p>YOLO v2则借用了Faster RCNN的anchor box思想。即预先设置好位置，然后通过预测该框的偏移来预测位置。（详见优化思路）</p>
<h2 id="优化思路"><a href="#优化思路" class="headerlink" title="优化思路"></a>优化思路</h2><h3 id="锚框（anchor-box）"><a href="#锚框（anchor-box）" class="headerlink" title="锚框（anchor  box）"></a>锚框（anchor  box）</h3><p>anchor box思想是Faster RCNN提出的（它改变了one-stage）。anchor box，顾名思义，锚框，像锚一些其基准的作用。</p>
<p>在anchor box提出之前，目标检测大多都是直接预测坐标的，这有很多缺点，比如不稳定、受到感受野限制等等。新的方法是首先在一张图片上铺满不同的锚框（主要是长宽比和大小不同）。</p>
<p>计算所有 anchor box 和 物体gt_box的 IoU。这样每一个anchor box的所负责预测类别便是与它IoU最大的那个gt_box。（附：当IoU小于某个阈值便作为负样本/背景样本）。</p>
<p>这样对物体的类别预测便是对anchor box类别的预测，对物体的位置的预测便是对anchor box位置的偏移的预测（对数偏移），其转换方法(YOLO v2)：</p>
<p><img src="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0%5C1567323883396.png" alt="1567323883396"></p>
<p>然而锚框也有很大缺点：</p>
<ul>
<li>大量的锚框加剧了不平衡现象</li>
<li>锚框的长宽比需要手动设计</li>
<li>网络中预测物体的感受野 与 实际物体的 不匹配现象（位置不匹配）：在网络中，anchor box通过对数偏移预测实际物体位置，然而网络中的感受野没有变化。</li>
</ul>
<h3 id="多尺度"><a href="#多尺度" class="headerlink" title="多尺度"></a>多尺度</h3><p>影响目标检测性能的有两个问题：</p>
<ol>
<li>位置不匹配：物体的实际位置 和 对于感受野的不匹配</li>
<li>尺度不匹配：小感受野预测大物体 或 大感受野预测小物体</li>
</ol>
<p>所以很多方法被提出来解决尺度不匹配问题。如下图所示：</p>
<p><img src="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0%5C1567324588539.png" alt="1567324588539"></p>
<ul>
<li>（a）是图片金子塔，将图片放缩成不同尺度来预测不同大小的物体，然而它有很多问题</li>
<li>（b）是老的目标检测网络用的backbone，只用最后一层来预测。尺度不匹配问题很严重</li>
<li>（c）是SSD提出的网络模型，使用最后几层不同尺度的特征图来预测物体，理论上小特征图的感受野大可以预测大物体，大特征图的感受野小，可以预测小物体。然而它有一个问题就是上层特征图可能对于信息的提取不充分。</li>
<li>（d）是特征金子塔，将深层特征图（语义信息充分，但缺乏空间信息）和浅层特征（空间信息充分，缺乏语义信息）融合。并将融合后的多尺度特征图预测物体。</li>
</ul>
<p>特征金子塔对于尺度不匹配问题有很好的解决。</p>
<h3 id="不平衡"><a href="#不平衡" class="headerlink" title="不平衡"></a>不平衡</h3><p>在目标检测中，样本主要分为入下几类：</p>
<ul>
<li>正/负 样本：正样本就是目标物体，负样本即背景物体</li>
<li>难/易 分样本：易分样本就是容易正确分类的样本，难分样本就是难以正确分类的样本</li>
</ul>
<p>不平衡问题也分为两类：</p>
<ul>
<li>正负样本不平衡：在训练集中，负样本占总体的比例很高。所以损失函数由负样本主导，不能很好对正样本进行优化。</li>
<li>难易样本不平衡：在训练集中，易分类样本远大于难分类样本，这些简单样本对损失函数和梯度的贡献很大，使得在迭代时不能够很好的优化。</li>
</ul>
<p>解决不平衡由很多方法，类似OHEM等，这里主要介绍何凯明提出的Focal loss：</p>
<p>传统的交叉熵的公式如下（二分类）：<br>$$<br>CE(p,y) =<br>\left{<br>\begin{array}{}<br>-log(p) \space\space\space\space\space\space\space\space\space\space\space\space if\space y = 1 \<br>-log(1-p) \space\space\space\space\space otherwise<br>\end{array}<br>\right.<br>$$<br>Focal loss的公式如下：<br>$$<br>FL(p)=<br>\left{<br>\begin{array}{}<br>-\alpha(1-p)^\gamma log(p)\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space if\space y = 1\<br>-(1-\alpha)(1-(1-p))^\gamma log(1-p)\space\space\space\space otherwise<br>\end{array}<br>\right.<br>$$<br>这里简化一下得到：<br>$$<br>\left{\begin{array}{}<br>FL(p_t) = -\alpha_t(1-p_t)^\gamma log(p_t)\<br>p_t = (y == 1\space?\space p\space:\space1-p)\<br>\alpha_t = (y == 1\space?\space \alpha\space:\space1-\alpha)\<br>\end{array}\right.<br>$$</p>
<p>相比于较叉熵，Focal loss加了两个参数：</p>
<ul>
<li>$\alpha$：$\alpha$是用来解决正负样本不平衡，它使得负样本的权重更小，正样本的权重更大</li>
<li>$(1-p_t)^\gamma$：$(1-p_t)^\gamma$是用来解决难易样本不平衡，$\gamma$是调制系数（一般$\gamma=2$）。当$1-p_t$ 越接近0，即代表该样本被正确分类，此时样本的权重越小。当$1-p_t$越小，说明该样本分类犯得错误越大，此时权重相对来说减小的更少，相当于变相的增加了权重。（$p_t = 0.99$损失小100倍，而$p_t = 0.5$仅缩小4倍）。</li>
</ul>
<h3 id="非极大值抑制（NMS）"><a href="#非极大值抑制（NMS）" class="headerlink" title="非极大值抑制（NMS）"></a>非极大值抑制（NMS）</h3><p>对于一个物体，神经网络可能会预测多个框，这些框围绕在gt_box附近。非极大值抑制就是为了抑制那些冗余的框，它的流程如下：</p>
<ul>
<li>将所有框的得分排序，选中最高分对应的框</li>
<li>遍历其余的框，如果和当前最高分框的重叠面积(IOU)大于一定阈值，我们就将框删除</li>
<li>从未处理的框中继续选一个得分最高的，重复上述过程，直到最后一个框。</li>
</ul>
<h2 id="经典模型"><a href="#经典模型" class="headerlink" title="经典模型"></a>经典模型</h2><h3 id="YOLO-v3"><a href="#YOLO-v3" class="headerlink" title="YOLO v3"></a>YOLO v3</h3><p>YOLO v3的网络结构如下：</p>
<p><img src="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0%5C1567501439402.png" alt="1567501439402"></p>
<p>其中DBL就是基本卷积结构（conv+BN+leaky），resn是一个残差结构，concat是一个拼接操作。</p>
<p>其中YOLO v3是多尺度的输出，有y1、y2、y3三个输出，如此可以有效缓解尺度不匹配的现象。</p>
<p>YOLO v3借用了anchor box思想。每个anchor box预测输出为【x,y,w,h,o】.</p>
<p>其损失函数是二元分类的交叉熵。</p>
<h3 id="Faster-RCNN"><a href="#Faster-RCNN" class="headerlink" title="Faster RCNN"></a>Faster RCNN</h3><p>Faster RCNN的网络结构如下：</p>
<p><img src="%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0%5C1567499632449.png" alt="1567499632449"></p>
<p>其网络主要分为三个部分：</p>
<ul>
<li>backbone：输入图片提取特征图</li>
<li>RPN：输入特征到RPN网络，对anchor进行二分类，其中正类就是有物体的，负类就是不含物体的。除了分类外，还对anchor进行第一次的位置回归，利用对数偏移调整anchor的位置。其中位置的损失函数是smooth L1，分类损失是交叉熵。</li>
<li>分类网络：将anchor按照RPN 网络的得分进行排序，剔除边界anchor、长宽过小的anchor，并进行NMS得到ROI。再通过ROI pooling输入分类回归网络，对ROI进行分类和第二次回归。</li>
</ul>
<p>smooth L1 loss的定义如下：<br>$$<br>smooth_{L1} =<br>\left{\begin{array}{}<br>0.5x^2\space\space\space\space\space\space\space\space if|x| &lt; 1\<br>|x|-0.5\space\space\space otherwise<br>\end{array}\right.<br>$$<br>其中x是预测框于gt_box之间的损失，其梯度为：<br>$$<br>smooth_{L1} =<br>\left{\begin{array}{}<br>x\space\space\space\space\space\space\space\space if|x| &lt; 1\<br>\pm1 \space\space\space\space\space otherwise<br>\end{array}\right.<br>$$<br>其好处是限制了梯度：</p>
<ul>
<li>当预测框与 ground truth 差别过大时，截断了梯度，使得梯度值不至于过大</li>
<li>当预测框与 ground truth 差别很小时，梯度值足够小</li>
</ul>
<h2 id="一些新的趋势（2018-2019）"><a href="#一些新的趋势（2018-2019）" class="headerlink" title="一些新的趋势（2018~2019）"></a>一些新的趋势（2018~2019）</h2><h3 id="anchor-free"><a href="#anchor-free" class="headerlink" title="anchor free"></a>anchor free</h3><p>技术的发展总是螺旋的。2017年，Faster RCNN提出的anchor机制以燎原之势占领了所有的目标检测的模型。而如今anchor free又成了新的研究热点。</p>
<p>anchor free的模型主要是通过特征点来确定预测box的。在corner-net中，作者提出通过检测一个物体的左上角和右下角来达到确定位置的效果。还有一些其他的例如预测中心点、四周点等等。这些预测特征点的方法和姿势检测，分割等领域相结合，成为了顶会的新宠儿。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>Recent Advances in Deep Learning for Object Detection</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/30/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%80%E5%8D%95%E7%BB%BC%E8%BF%B0/" data-id="ck21ppygr000jk4qnfg6h9c28" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-神经网络与优化器" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/09/30/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8/" class="article-date">
  <time datetime="2018-09-30T03:28:43.000Z" itemprop="datePublished">2018-09-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/09/30/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8/">神经网络与优化器</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="神经网络与优化器"><a href="#神经网络与优化器" class="headerlink" title="神经网络与优化器"></a>神经网络与优化器</h1><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="神经网络的结构"><a href="#神经网络的结构" class="headerlink" title="神经网络的结构"></a>神经网络的结构</h3><p>神经网络的结构可以用下图展示：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8%5C02.png" alt="img"></p>
<p>上图结构表明，一个神经网络由三个部分构成：</p>
<ul>
<li>输入层：x1 x2 x3，即黄色节点</li>
<li>隐藏层：蓝色节点</li>
<li>输出层：y1 y2 y3，即蓝色节点</li>
</ul>
<p>这里的节点用于存储值（一般存储前向的计算值和反向的梯度），节点之间的连线被赋予相应的权重，代表着一个节点的值通过对应线（即乘以该线的权重）汇聚到下一层的节点，该节点的值即为所有通过链接到该节点的线值之和。</p>
<p>这里可以用矩阵乘法表达出来：</p>
<ul>
<li><p>输入X = [x1,x2,x3,x4]</p>
</li>
<li><p>输入层到第一层连线的权重为W:<br>$$<br>\begin{matrix}<br>w11 &amp; w12 &amp; w13 &amp; w14\<br>w21 &amp; w22 &amp; w23 &amp; w24\<br>w31 &amp; w32 &amp; w33 &amp; w34\<br>w41 &amp; w42 &amp; w43 &amp; w44\<br>\end{matrix}<br>$$</p>
</li>
<li><p>则第一层的值 $X‘ = X*W$ （附：这里没有用到 b）</p>
</li>
</ul>
<p>故神经网络可以用矩阵乘法表示：$Y = W_n<em>W_{n-1}</em>…<em>W_1</em>X$，这里Y就是神经网络的输出</p>
<h3 id="反向传播与梯度下降"><a href="#反向传播与梯度下降" class="headerlink" title="反向传播与梯度下降"></a>反向传播与梯度下降</h3><p>机器学习（深度学习）的过程可以用如下的图表示：<img src="D:%5Cblog%5Csource_posts%5C%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8%5C041033589217526.png" alt="img"></p>
<p>在特征集$X$和输出结果$Y$之间有一个关系，这个关系可以通过目标函数$f$，深度学习就是通过深度神经网络以及训练样本去拟合这个函数。其中拟合的过程可以描述为，我们确定一个损失函数$L$，来度量我们模型输出$Y’$和实际结果$Y$的差异，其中$L$越小即说明差异越小，即代表我们的模型越接近于目标函数$f$（至少是在训练集上接近，而只要训练集足够大，那么训练集的目标函数和总体样本的目标函数就越小，所以我们可以认为我们拟合的模型有足够的普适性）。</p>
<p>对于深度学习而言，学习目标可以描述为寻找到合适的参数使得神经网络的损失函数最小，而该神经网络即为我们需要的模型：<br>$$<br>min_wLoss(Y,Y’,w)<br>$$</p>
<h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>在学习的过程中，减小损失函数$L$的方法就是梯度下降。</p>
<p>梯度下降可以用小人下山等易理解的方法阐述，其他博客说的已经很详细。在这里，我使用一个更公理化的方法来描述它（泰勒展开式）</p>
<p>我们知道，任意一个函数可以一阶展开为如下形式：<br>$$<br>f(x) = f(x_0)+f’(x_0)(x-x_0)+R<br>$$<br>而我们的目标是使得$f(x)$变得更小：<br>$$<br>f(x_1)-f(x_0) &lt; 0<br>$$<br>即可以看成：<br>$$<br>f’(x_0)(x_1-x_0)+R &lt; 0<br>$$<br>忽略R，可以得到$f’(x_0)(x_1-x_0) &lt; 0$，即$(x1 - x0)$和$f’(x)$成钝角（一般设为$180^o$）即：<br>$$<br>x_1-x_0 = -\alpha*f’(x0)<br>$$<br>其中$\alpha$调节下降速率。</p>
<p>对于损失函数而言，更新过程即为：<br>$$<br>w_{k+1} = w_k-\alpha*L’(w_k,Y,Y’)<br>$$</p>
<h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><p>梯度下降的过程就是不断的迭代求梯度，更新权重w。而对于神经网络而言，如何求出每一个权重的梯度是一个很大的难题。</p>
<p>反向传播是一种利用链式法则求出梯度的过程，其中反向传播的描述其它博客叙述的很详尽了。这里就不更详细的描述了。</p>
<h4 id="一些更智慧的学习方法"><a href="#一些更智慧的学习方法" class="headerlink" title="一些更智慧的学习方法"></a>一些更智慧的学习方法</h4><ol>
<li><p>batch不同</p>
<p>梯度下降就是不断求梯度，更新参数w的过程。那么这个求梯度的损失函数的输入是什么？</p>
<p>其中批量梯度下降（BGD），就是求所有训练样本的的梯度，然后更新w。但是这有一个缺点，就是训练样本往往数据量很大，所以求一次全部损失之和然后再求梯度会很慢，其公式如下：<br>$$<br>w = w-\alpha<em>\nabla_w\sum_{i\in Trainning}{loss(Y_i,Y’_i,w)}<br>$$<br>所以有人提出了随机梯度下降（SGD），即每次以一个样本来更新参数。这样会很快，但是由于样本的分布问题会使得损失函数不停的震荡。<br>$$<br>w = w-\alpha</em>\nabla_wloss(Yi,Yi’,w)<br>$$<br>小批量梯度下降是BGD和SGD的折中办法，它每次迭代以一个固定batch_size的样本数量来更新参数。</p>
</li>
<li><p>对计算梯度的改进</p>
<p>SGD的一大问题是不停震荡，即梯度方向不停变化，不是一直朝着谷底。这里有研究者提出一种称为动量的技术（Momentum）的技术来对梯度中相关方向进行优化以及无关方向的弱化。在这种方法中，更新的梯度$v(t)$是：<br>$$<br>v_{t} = \gamma*v_{t-1}+\nabla loss(w_{t-1})<br>$$<br>即反复梯度中反复震荡的方向被消减，而梯度一直不变的方向通过累加不断增强。</p>
</li>
</ol>
<p>   Nesterov梯度下降法是一种针对动量的改进方法。其主要改进思路是：动量法利用当前梯度和历史梯度来生成梯度，而该方法是利用历史梯度和下一次的梯度来生成梯度。其更新的公式为：<br>   $$<br>   v_t = \gamma<em>v_{t-1}+\nabla loss(w - \alpha</em>\gamma*v_{t-1})<br>   $$</p>
<ol start="3">
<li><p>对设定学习率的改进</p>
<p>Adagrad 算法能够在算法训练中自适应的调整各个参数的学习率。其调整策略为：对于那些出现次数较高的参数，lr 更小；出现次数较低的参数，lr更大。</p>
<p>其具体的步骤是，设置一个矩阵G，对每次更新的梯度进行累加，公式为：<br>$$<br>G = G + gra \cdot gra<br>$$<br>更新公式如下，其中 i 表示 w 中第 i 个参数，矩阵G中索引为 ii 的数。<br>$$<br>w_{t,i} = w_{t-1,i} - \frac{lr}{\sqrt{G_{t,ii}+\epsilon}}*gra<br>$$<br>Adagrad有一个缺陷就是累加矩阵G总是会变大的，所以造成学习速率总会下降。如果多次累加后导致最好学习率接近0，会使得训练提前结束。</p>
</li>
</ol>
<p>   RMSprop是Hinton 提出的另一种自适应学习率的方法。Adagrad是对所有历史梯度进行累加，而RMSprop则是计算梯度的平均值。</p>
<p>   平均值的求取公式为：<br>   $$<br>   E(g^2)<em>t = 0.9*E(g^2)</em>{t-1}+0.1<em>g_t^2<br>   $$<br>   更新公式为：<br>   $$<br>   w_t = w_{t-1}-\frac{lr}{\sqrt{E[g^2]_t+\epsilon}}</em>gt<br>   $$</p>
<ol start="4">
<li><p>Adam-集大成者</p>
<p>Adam集合了动量和自适应学习率的全部优点。</p>
<p>Adam种梯度的更新方式如下，和动量法很像，其中更新后的梯度用m表示<br>$$<br>m_t = \beta1<em>m_{t-1}+(1-\beta1)</em>g_t<br>$$<br>Adam用v表示历史梯度平均值，其更新公式如下：<br>$$<br>v_t = \beta2<em>v_{t-1}+(1-beta2)</em>g_t^2<br>$$<br>修正$m_t$和$v_t$，使其变成无偏估计量：<br>$$<br>\hat{m_t} = \frac{m_t}{1-\beta1^t}\<br>\hat{v_t} = \frac{v_t}{1-\beta2^t}<br>$$<br>更新参数：<br>$$<br>w_{t+1} = w_t - \frac{lr}{\sqrt{\hat{v_t}}+\epsilon}<br>$$</p>
</li>
</ol>
<h3 id="激励函数"><a href="#激励函数" class="headerlink" title="激励函数"></a>激励函数</h3><p>上一节得到神经网络可以用如下数学公式表示：$Y = W_n<em>W_{n-1}</em>…<em>W_1</em>X$。然而很明显的是这个公式中只有矩阵乘法，即它只能描述线性关系。</p>
<p>而激励函数就是为了解决这一问题提出的。在加入了激励函数的神经网络中，隐含层的节点中的值并不会直接输出，而是通过激励函数之后再输出，即数学公式变成了：</p>
<p>$$<br>Y = active(W_n<em>active(W_{n-1}</em>…<em>active(W_1</em>X)…))<br>$$<br>激励函数一般不是简单的线性函数，所以改进后的神经网络描述关系的能力更加强大。常见的激励函数有sigmoid函数，tanh函数和relu系列函数</p>
<h4 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h4><p>Sigmoid函数是<br>$$<br>f(x) = \frac{1}{1+e^{-x}}<br>$$</p>
<p>其函数图像为：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8%5Cwebp" alt="img"></p>
<p>Sigmoid 函数有三个缺点：</p>
<ul>
<li>sigmoid函数的两级的梯度为0，容易造成梯度消失的情况</li>
<li>不以0为中心，这样对w而言的求导要么全负，要么全正，所以会导致zig zag path更新（$w_k$的局部梯度是$x_k*gra_{k+1}$，而$x_k$是由上一层的sig函数输出，全大于0）</li>
<li>反向传播计算梯度复杂</li>
</ul>
<h4 id="tanh"><a href="#tanh" class="headerlink" title="tanh"></a>tanh</h4><p>tanh函数是：<br>$$<br>tanh(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}}<br>$$<br>其函数图像为：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8%5C1566725249985.png" alt="1566725249985"></p>
<p>tanh函数解决了zero-centered的输出问题，然而还是有梯度消失和反向传播复杂的问题</p>
<h4 id="Relu系列"><a href="#Relu系列" class="headerlink" title="Relu系列"></a>Relu系列</h4><p>Relu的初始函数：<br>$$<br>Relu = max{0,x}<br>$$<br>其函数图像为：</p>
<p><img src="%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8%5C1566725389294.png" alt="1566725389294"></p>
<p>Relu函数最大的好处就在于它的简洁，这使得它在前向和后向传播的时候非常快。同时它也避免了梯度消失的问题。但是Relu也有一些缺点：</p>
<ul>
<li>不是zero-centered</li>
<li>ReLU函数将小于0的值提高到0，这使得一些小于0的节点失活</li>
</ul>
<p>Leaky ReLU就是为了解决节点失活的问题，它设小于0部分的斜率为$\alpha$,而不是直接等于0。其函数表达式为：<br>$$<br>f(x) = max(\alpha*x,x)<br>$$</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/09/30/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8/" data-id="ck21ppygv000nk4qn6wfm9utx" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-关于局部最优解和全局最优解的dp问题" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/29/%E5%85%B3%E4%BA%8E%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A3%E5%92%8C%E5%85%A8%E5%B1%80%E6%9C%80%E4%BC%98%E8%A7%A3%E7%9A%84dp%E9%97%AE%E9%A2%98/" class="article-date">
  <time datetime="2018-07-29T01:32:28.000Z" itemprop="datePublished">2018-07-29</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">数据结构与算法</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/29/%E5%85%B3%E4%BA%8E%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A3%E5%92%8C%E5%85%A8%E5%B1%80%E6%9C%80%E4%BC%98%E8%A7%A3%E7%9A%84dp%E9%97%AE%E9%A2%98/">关于局部最优解和全局最优解的dp问题</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>今天刷leetcode时遇到一个dp问题，然后却无法完美的找出递推关系式（附：以后要多做，以期能够熟练的掌握dp）<br>题目如下：Maximum Subarray</p>
<blockquote>
<p>Given an integer array nums, find the contiguous subarray (containing at least one number) which has the largest sum and return its sum.</p>
</blockquote>
<p>在我想维护一个dp数组来找到结果时却没有思路，无奈只好求助于Google，幸而学到了一点东西</p>
<h1 id="全局最优解和局部最优解"><a href="#全局最优解和局部最优解" class="headerlink" title="全局最优解和局部最优解"></a>全局最优解和局部最优解</h1><p>在这里，我们需要维护两个变量，一个是全局最优global，就是到当前元素为止最优的解是，一个是局部最优，就是必须包含当前元素的最优的解local。</p>
<p>在这道题当中，我们知道nums[0]~nums[i-1]的最大和，如何求出到nums[i]的最大和呢？这里可以分为两种情况</p>
<ul>
<li>在nums[i]的最大和中不包含nums[i],那么global[i] = global[i-1]</li>
<li>在nums[i]的最大和中不包含nums[i],那么global[i] = local[i] = nums[i]+local[i-1]</li>
</ul>
<p>由上述两种情况便可以推出来递推式：</p>
<ul>
<li>local[i+1]=max(A[i], local[i]+A[i])</li>
<li>global[i+1]=max(local[i+1],global[i])</li>
</ul>
<p>由此便可以得到代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSubArray</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        length = len(nums)</span><br><span class="line">        local_num = nums[<span class="number">0</span>]</span><br><span class="line">        global_num = nums[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,length):</span><br><span class="line">            local_num = max(nums[i],nums[i]+local_num)</span><br><span class="line">            global_num = max(local_num,global_num)</span><br><span class="line">        print(global_num)</span><br></pre></td></tr></table></figure>

<h1 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h1><p>动态规划的局部变量和全局变量问题本质上就是就是，以数组为例：当数组向前推进，引入新的元素，原有的解会可能会因为新的元素发生变化。而局部变量就是包含新加入的元素的解。</p>
<p>一个新的变种问题：买卖股票问题</p>
<blockquote>
<p>在一个数组中，第i个元素表示第i天的股价。你可以买卖股票，求出最大利润</p>
</blockquote>
<p>这实际上就是一个需要用到局部变量和全局变量的问题。局部变量表示在今天卖出的最佳交易,即在今天卖出，在之前最小的数时买入。<br>递推式子：</p>
<ul>
<li>local[i] = max(local[i-1]-nums[i-1]+nums[i],0) </li>
<li>global[i] = max(global[i-1],local[i])</li>
</ul>
<p>由此便可以得出代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span><span class="params">(self, prices)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type prices: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        local = <span class="number">0</span></span><br><span class="line">        _global = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(prices)):</span><br><span class="line">            local = max(local+prices[i]-prices[i<span class="number">-1</span>],<span class="number">0</span>)</span><br><span class="line">            _global = max(_global,local)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> _global</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/29/%E5%85%B3%E4%BA%8E%E5%B1%80%E9%83%A8%E6%9C%80%E4%BC%98%E8%A7%A3%E5%92%8C%E5%85%A8%E5%B1%80%E6%9C%80%E4%BC%98%E8%A7%A3%E7%9A%84dp%E9%97%AE%E9%A2%98/" data-id="ck21ppygl0008k4qnd7wg2pao" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dp/" rel="tag">dp</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/leetcode%E6%80%BB%E7%BB%93/" rel="tag">leetcode总结</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-动态规划及其两种方法" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/07/26/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%8F%8A%E5%85%B6%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/" class="article-date">
  <time datetime="2018-07-26T11:40:24.000Z" itemprop="datePublished">2018-07-26</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">数据结构与算法</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/26/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%8F%8A%E5%85%B6%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/">动态规划及其两种方法</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="动态规划及其两种方法"><a href="#动态规划及其两种方法" class="headerlink" title="动态规划及其两种方法"></a>动态规划及其两种方法</h1><p>在今天刷leetcode时遇到一个问题：</p>
<blockquote>
<p>Given a m x n grid filled with non-negative numbers, find a path from top left to bottom right which minimizes the sum of all numbers along its path.</p>
</blockquote>
<p>  首先我想到迪杰斯特拉算法，然而这算法时间复杂度太高。遂求解于Google，发现可以用动态规划方法求解，于是便复习了一波动态规划，并记录下来一些东西。</p>
<h2 id="动态规划的基本原理"><a href="#动态规划的基本原理" class="headerlink" title="动态规划的基本原理"></a>动态规划的基本原理</h2><h3 id="什么是动态规划"><a href="#什么是动态规划" class="headerlink" title="什么是动态规划"></a>什么是动态规划</h3><p>什么是动态规划，动态规划（下称dp）本质上是一个通过将问题分解为数个子问题的方式来求解问题的方法。即对于一个复杂的问题，我们求解不出来，可以将他分解为简单的子问题来单独求解。</p>
<h3 id="动态规划的适用情况"><a href="#动态规划的适用情况" class="headerlink" title="动态规划的适用情况"></a>动态规划的适用情况</h3><blockquote>
<ul>
<li>最优子结构性质。如果问题的最优解所包含的子问题的解也是最优的，我们就称该问题具有最优子结构性质（即满足最优化原理）。最优子结构性质为动态规划算法解决问题提供了重要线索。</li>
<li>无后效性。即子问题的解一旦确定，就不再改变，不受在这之后、包含它的更大的问题的求解决策影响。</li>
<li>子问题重叠性质。子问题重叠性质是指在用递归算法自顶向下对问题进行求解时，每次产生的子问题并不总是新问题，有些子问题会被重复计算多次。动态规划算法正是利用了这种子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存在一个表格中，当再次需要计算已经计算过的子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。</li>
</ul>
</blockquote>
<p>  上述是wiki上的描述，比较复杂。简单点说就是可以将总问题分解成一些子问题，并可以通过子问题的解来得到总问题的最优解。</p>
<h3 id="动态规划的实际使用"><a href="#动态规划的实际使用" class="headerlink" title="动态规划的实际使用"></a>动态规划的实际使用</h3><p>这里我们使用斐波拉契数列作为例子来求解。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">   function fib（n）</span><br><span class="line">       <span class="keyword">if</span> n = <span class="number">0</span> <span class="keyword">or</span> n = <span class="number">1</span></span><br><span class="line">           <span class="keyword">return</span> n</span><br><span class="line">       <span class="keyword">return</span> fib(n − <span class="number">1</span>) + fib（n − <span class="number">2</span>）</span><br><span class="line">`</span><br></pre></td></tr></table></figure>



<p>  由上图可知，对于斐波拉契的求解，我们可以将其分解为几个子问题求解。并且其中还有几个重复的子问题，为了提高性能，有两种方法可以避免子问题的重复求解</p>
<ul>
<li><p><strong>自顶向下的备忘录法</strong></p>
</li>
<li><p><strong>自底向上的动态规划</strong></p>
</li>
</ul>
<h3 id="自顶向下的备忘录法"><a href="#自顶向下的备忘录法" class="headerlink" title="自顶向下的备忘录法"></a>自顶向下的备忘录法</h3><p>自顶向下的备忘录发就是在求解动态规划问题时设置一个备忘录，将所有求解过的子问题结果存储下来。在之后遇到1同样的问题时便可以避免重复求解。</p>
<h3 id="自底向上的动态规划"><a href="#自底向上的动态规划" class="headerlink" title="自底向上的动态规划"></a>自底向上的动态规划</h3><p>自底向上就是要合理安排子问题的求解顺序，使的子问题不会被重复提出。例如上面的斐波拉契问题，就可以</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public static int fib(int n)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="keyword">if</span>(n&lt;=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> n;</span><br><span class="line">        int []Memo=new int[n+<span class="number">1</span>];</span><br><span class="line">        Memo[<span class="number">0</span>]=<span class="number">0</span>;</span><br><span class="line">        Memo[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(int i=<span class="number">2</span>;i&lt;=n;i++)</span><br><span class="line">        &#123;</span><br><span class="line">            Memo[i]=Memo[i<span class="number">-1</span>]+Memo[i<span class="number">-2</span>];</span><br><span class="line">        &#125;       </span><br><span class="line">        <span class="keyword">return</span> Memo[n];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接下来求解leetcode原题：</p>
<blockquote>
<p>Given a m x n grid filled with non-negative numbers, find a path from top left to bottom right which minimizes the sum of all numbers along its path.<br>You can only move either down or right at any point in time.</p>
</blockquote>
<p>  思路：在ij点的长度len[i][j] = matrix[i][j]+min{len[i-1][j],len[i][j-1]}，我们使用第二种方法来合理的安排求解len[i][j]的顺序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minPathSum</span><span class="params">(self, grid)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type grid: List[List[int]]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        width = len(grid[<span class="number">0</span>])</span><br><span class="line">        length = len(grid)</span><br><span class="line">        n_dp = min(width,length)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,width):</span><br><span class="line">              grid[<span class="number">0</span>][i] = grid[<span class="number">0</span>][i]+grid[<span class="number">0</span>][i<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,length):</span><br><span class="line">              grid[i][<span class="number">0</span>] = grid[i][<span class="number">0</span>]+grid[i<span class="number">-1</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n_dp):</span><br><span class="line">            grid[i][i] += min(grid[i][i<span class="number">-1</span>],grid[i<span class="number">-1</span>][i])</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,width):</span><br><span class="line">                grid[i][j] += min(grid[i<span class="number">-1</span>][j],grid[i][j<span class="number">-1</span>])</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>,length):</span><br><span class="line">                grid[j][i] += min(grid[j<span class="number">-1</span>][i],grid[j][i<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">return</span> grid[<span class="number">-1</span>][<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2018/07/26/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%8F%8A%E5%85%B6%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95/" data-id="ck21ppygn000ck4qndpw718xr" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dp/" rel="tag">dp</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/leetcode%E6%80%BB%E7%BB%93/" rel="tag">leetcode总结</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">数据结构与算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E8%B0%88/">杂谈</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/cv/" rel="tag">cv</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dp/" rel="tag">dp</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/leetcode%E6%80%BB%E7%BB%93/" rel="tag">leetcode总结</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/" rel="tag">linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" rel="tag">环境配置</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" rel="tag">神经网络</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/cv/" style="font-size: 10px;">cv</a> <a href="/tags/dp/" style="font-size: 20px;">dp</a> <a href="/tags/leetcode%E6%80%BB%E7%BB%93/" style="font-size: 15px;">leetcode总结</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/" style="font-size: 10px;">环境配置</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 10px;">神经网络</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/10/">十月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/06/">六月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">十月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/09/">九月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/07/">七月 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/10/22/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2019/06/23/0-1%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/">0-1背包问题</a>
          </li>
        
          <li>
            <a href="/2018/10/20/ubuntu18-04-cuda-cudnn-Anaconda-%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%B7%A5%E6%99%BA%E9%9A%9C%E7%9A%84%E8%87%AA%E6%88%91%E4%BF%AE%E5%85%BB/">ubuntu18.04----cuda,cudnn,Anaconda,一个人工智障的自我修养</a>
          </li>
        
          <li>
            <a href="/2018/10/19/ubuntu18-04-%E5%9F%BA%E6%9C%AC%E5%AE%89%E8%A3%85%E4%B8%8E%E7%BE%8E%E5%8C%96/">ubuntu18.04----基本配置与美化</a>
          </li>
        
          <li>
            <a href="/2018/09/30/Batch%20Normalization/">Batch Normlization</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Autumn-Cat<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>